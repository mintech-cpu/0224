#!/usr/bin/env python
# coding: utf-8

# # 【第6回】不動産ページから情報取得する①
# 
# これまでの講義では、`Requests`と`BeautifulSoup`を使ったスクレイピングの基礎知識を学んできました。
# 
# 今回は集大成ということで、賃貸情報が掲載されているSUUMO(新宿区)のWebサイトから、自分が欲しい情報を抽出していきたいと思います。
# 
# https://suumo.jp/chintai/tokyo/sc_shinjuku/
# 
# 実際のサイトを使って情報抽出するので少し難しくなります。一度にすべてをマスターしようとせず、何回も動画を見返して習得していきましょう！
# 
# *※動画の感想を、僕のTwitterにメンションしてツイートしていただけると嬉しいです（ ;  ; ）！*
# 
# Twitter : [@hayatasuuu](https://twitter.com/hayatasuuu)

# # スクレイピングが禁止されていないか確認する
# 
# 「さっそくスクレイピング...」と言いたいところですが、まずはスクレイピング可能なサイトなのか確認しておきましょう。
# 
# *※動画で紹介するくらいなので、今回使っていくSUUMOのサイトはスクレイピングしても問題ありません。でも、応用で他のサイトに対してスクレイピングするとき、役に立つ知識になります。*
# 
# スクレイピングの可否は、利用規約のページを見ていきましょう。
# 
# https://suumo.jp/edit/kiyaku/
# 
# 僕は利用規約のページで、以下のキーワードを検索することが多いです。
# 
# - 自動
# - ロボット
# - クローリング
# - スクレイピング
# 
# 英語のサイトであれば、以下のキーワードになります。
# 
# - auto
# - robot
# - crawling
# - scraping
# 
# SUUMOのページでは、これらに該当する事項がありませんので、特に禁止されていません。
# 
# ただ、ユーザーの禁止事項にもあるとおり、高負荷をかけてしまうと「(6) 本サイトの運営を妨げる行為」に該当しますので注意しましょう。

# # まずは小さく情報取得してみる
# 
# スクレイピングで情報取得するとき、forループを使って繰り返し処理をすることが多いです。
# 
# でもまずは、forループを使わないでデータを取ってみましょう！
# 
# - 小さく情報取得してみる
# - 大丈夫そうだったらforループする
# 
# この手順で進めていこうと思います。

# ## ライブラリのインポート
# 
# まずは、ライブラリのインポートからやっていきます。
# 
# とは言っても、いつもとやることは変わりません。`Requests`と`BeautifulSoup`をインポートしていきましょう。

# In[2]:


from bs4 import BeautifulSoup
import requests


# ## RequestsでURLにアクセスしてHTMLを解析する
# 
# 次に`Requests`を使ってURLにアクセスし、HTMLを取得して解析していきます。
# 
# URLは`https://suumo.jp/chintai/tokyo/sc_shinjuku/`ですが、今回は以下のように書いておきたいと思います。

# In[3]:


# 変数urlにSUUMOホームページのURLを格納する
url = 'https://suumo.jp/chintai/tokyo/sc_shinjuku/?page={}'


# アクセスするためのURLをtarget_urlに格納する
target_url = url.format(1)

# print()してtarget_urlを確認する
print(target_url)


# このように、`?page={]`を付けて、あとから`format`を使ってURLを作成しました。
# 
# 最初から`url = 'https://suumo.jp/chintai/tokyo/sc_shinjuku/?page=1'`のように書かない理由は、2ページ目以降にアクセスするとき、forループを使っていくためです。
# 
# <br>
# 
# 
# というのも、2ページ目のURLは`https://suumo.jp/chintai/tokyo/sc_shinjuku/?page=2`になっています。
# 
# それ以降のページに関しても`?page=3`のように、数字が変更されるだけです。
# 
# <br>
# 
# 数字だけ変更すれば使い回しできるってわけですね。
# 
# 今回はまだforループを使わないでデータを取っていきますので、この`target_url`にアクセスしていきましょう。

# In[4]:


# target_urlへのアクセス結果を、変数rに格納

r = requests.get(target_url)


# 取得結果を解析してsoupに格納
soup = BeautifulSoup(r.text)


# この部分はいつもどおりですね。
# 
# あとは`soup`に対して`find()`や`find_all()`を使って情報を取得するだけです！

# ## soupから情報を抽出する
# 
# まずは、各賃貸情報がどのような形で格納されているか確認しましょう。
# 
# Webページで「検証」を開くと、HTMLの構造を閲覧できます。
# 
# <br>
# 
# HTMLを確認すると、それぞれの賃貸情報は`div`タグの`cassetteitem`に格納されていることが分かります。
# 
# まずは各賃貸情報をすべて取得して、その後でそれぞれのブロックから情報を抽出するようにしましょう。
# 
# すべてのタグ情報をクラス付きで指定する方法は、前回やった`find_all(タグ名, class_='')`ですね！

# In[5]:


# cassetteクラスを持ったdivタグをすべて取得して、変数contentsに格納
contents = soup.find_all('div', class_="cassetteitem")


# これで、`cassetteitem`を持つすべての`div`タグを取得できました。
# 
# SUUMOのページでは、デフォルトで1ページあたり20件の賃貸情報が掲載されているようです。
# 
# `find_all()`で取得した結果は、Pythonリスト形式になっているので、`len()`を使えば中身の要素数を確認できます。

# In[7]:


# 変数contentsの中身を確認する
len(contents)


# ちゃんと賃貸情報のブロックを取得できていますね。
# 
# いまはforループを使わないでコード作成したいので、変数`content`の中に最初の要素を格納しておきましょう。

# In[8]:


# 変数contentにcontentsの最初の要素を格納する
content = contents[0]


# あとは、最初のブロックに入っている賃貸情報から、自分が欲しい情報を取得していくだけです。
# 
# このページからは色々な情報を抽出できますが、今回は以下の項目を取得したいと思います。
# 
# - 物件情報
#   - 物件名
#   - 住所
#   - アクセス
#   - 築年数
# - 部屋情報
#   - 物件の階数
#   - 物件の賃料/管理費
#   - 物件の敷金・礼金
#   - 物件の間取り・面積

# ### 物件情報と部屋情報が入ったブロックを取得する
# 
# 賃貸情報のブロックを確認すると、「物件・建物の情報」と「各部屋の情報」で格納されているタグが、別になっていることが分かります。
# 
# あとで詳細情報を取り出しやすいように、それぞれの情報を変数に格納しておきましょう。

# In[9]:


# 物件・建物情報を変数detailに格納する
detail = content.find('div', class_="cassetteitem-detail")

# 各部屋の情報を変数tableに格納する
table = content.find('table', class_="cassetteitem_other")


# こうしておくと、毎回`find()`以降を書かずに済みます。

# ### 物件情報を抽出する
# 
# ということで、まずは物件情報を取得していきましょう。
# 
# 物件情報で取得できるのは、以下の部分です。
# 
# - 物件名
# - 住所
# - アクセス
# - 築年数
# 
# これらの情報を取得するには、SUUMOのホームページで「検証」をクリックして、どこのタグに格納されているのか確認する必要があります。
# 
# <br>
# 
# どのタグに格納されているのか確認できたら、取得結果を変数に格納してあげましょう。

# In[12]:


# 変数titleに、物件名を格納する
title = detail.find('div', class_="cassetteitem_content-title").text

# 変数addressに住所を格納する
address = detail.find('li', class_="cassetteitem_detail-col1").text

# 変数accessにアクセス情報を格納する
access = detail.find('li', class_="cassetteitem_detail-col2").text

# 変数ageに築年数を格納する
age = detail.find('li', class_="cassetteitem_detail-col3").text


# 取得結果を格納できたら、実際に中身を見てみましょう。

# In[13]:


# 各変数の取得結果を確認
title, address, access, age


# しっかりと中身を取得できていますね！
# 
# *※途中で改行記号(`\n`)などが入っていますが、それらは無視して大丈夫です。*
# 

# ### 部屋情報を抽出する
# 
# 次は各部屋の情報を取得していきましょう。
# 
# 変数`table`に格納しておいたHTMLの解析結果から、以下の情報を取得していきたいと思います。
# 
# - 物件の階数
# - 物件の賃料/管理費
# - 物件の敷金・礼金
# - 物件の間取り・面積
# 
# 各部屋の情報は`<table>`タグに囲まれているので、`<tr>`を見てあげると1つの部屋情報になっているはずです。
# 
# *※`<tr>`はtable rowの省略で、`<table>`タグの行(横一列)のことです。SUUMOのページを見ると、1つ1つの部屋情報は、横1列に並んでいるかと思います。*
# 
# なので、テーブルから部屋情報を抽出するときは、複数の`<tr>`タグを見てあげる必要があります。
# 
# <br>
# 
# 複数の`<tr>`タグを抽出するには...。そうです、`find_all()`を使って取得していきます。
# 
# さらに習得した結果はリストになっていますので、今回は最初の1つ(=インデックス番号0)だけ取得してみましょう。

# In[18]:


# 変数tableからすべてのtrタグを取得して、変数tr_tagsに格納
tr_tags = table.find_all('tr', class_="js-cassette_link")

# tr_targsの中から最初の1つだけtr_tagに格納
tr_tag = tr_tags[0]


# これで、複数の部屋情報から、1つの部屋情報だけ取得できました。
# 
# あとは、変数`tr_tag`から以下4つの情報を取得するだけです。
# 
# - 物件の階数
# - 物件の賃料/管理費
# - 物件の敷金・礼金
# - 物件の間取り・面積

# ### 演習
# 
# 変数`tr_tag`から、以下の情報を取得してみましょう。
# 
# - 物件の階数
# - 物件の賃料/管理費
# - 物件の敷金・礼金
# - 物件の間取り・面積
# 
# *※参考程度に、僕の方で作成してある答えは、1行で書けるコードになっています！*
# 
# こちらの答えあわせは、次回の動画で解説していきますね！

# In[ ]:




